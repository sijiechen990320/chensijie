import numpy as np
from sklearn.base import BaseEstimator,ClusterMixin
import networkx as nx
import pandas as pd

# h是窗口带宽 平滑参数 窗口里的影响大 窗口外的影响小
# consi 最小密度阈值 eps 迭代时两点最小的容差值
# 一个数据集+三个超参数
# 存放密度吸引子集合的初始化
# 迭代到两xi xi+1之间差小于阈值 若x大于密度阈值 把x(密度吸引子)传回去 A
# 求两两可达的密度吸引子的极大可能子集（山峰之间的合并） 两两比较是否连通  C
# 把密度吸引子的小弟遍并到一个类簇
# 梯度上升 计算加权影响的时候可以忽略远点的影响 设立半径r  只考虑里面的点 r=h(标准差)*z

#找到密度吸引子
def _hill_climb(x_t,X,W=None,h=0.1,eps=1e-7):
    error=99.
    prob=0.
    x_l1=np.copy(x_t)
    #建立了密度吸引子的工作范围
    radius_new=0.
    radius_old=0.
    radius_twiceold=0.
    iters=0.
    while True:
        radius_thriceold=radius_twiceold
        radius_twiceold=radius_old
        radius_old=radius_new
        x_l0=np.copy(x_l1)
        x_l1,density=_step(x_l0,X,W=W,h=h)
        error=density-prob
        prob=density
        radius_new=np.linalg.norm(x_l1-x_l0) #范数
        radius=radius_thriceold+radius_twiceold+radius_old+radius_new
        iters+=1
        if iters>3 and error<eps:
            break
    return [x_l1,prob,radius]

#计算X(t+1)
def _step(x_l0,X,W=None,h=0.1):
    n=X.shape[0]  #行
    d=X.shape[1]  #列
    superweight=0.   #权重
    x_l1=np.zeros((1,d))
    if W is None:
        W=np.ones((n,1))
    else:
        W=W
    for i in range(n):
        kernel=kernelize(x_l0,X[j],h,d)
        kernel=kernel*W[j]/(h**d)
        superweight=superweight+kernel
        x_l1=x_l1+(kernel*X[j])
    x_l1=x_l1/superweight
    density=superweight/np.sum(W)
    return [x_l1,density]

#计算高斯核
def kernelize(x,y,h,degree):
    kernel=np.exp(-(np.linalg.norm(x-y)/h)*2./2.)/((2.*np.pi)**(degree/2))
    return kernel

class DENCLUE(BaseEstimator,ClusterMixin):
    #h 高斯核的平滑参数 超参数 默认值为np.std(X)/5
    #eps 迭代最小的容差值 集合密度吸引点的门槛
    #min_density 不被定位噪声点的密度吸引点的最小核密度 -1将表示为噪音
    #数据本身决定核密度 默认为0
    #metric 在特征数组里度量距离 这里采用欧氏距离
    #cluster_info 包括所有聚类的相关信息，即使被认定噪声点也储存在里面
    #labels_ 每个点的簇标签 噪声为1
    def _init_(self,h=None,eps=1e-8,min_density=0,metric='euclidean'):
        self.h=h
        self.eps=eps
        self.min_density=min_density
        self.metric=metric

    def classify(self,X,y=None,sample_weight=None):
        if not self.eps>0.0:
            raise ValueError("eps must be positive")
        self.n_samples=X.shape[0]
        self.n_features=X.shape[1]
        density_attractors=np.zeros((self.n_samples,self.n_features))
        radii=np.zeros((self.n_samples,1))
        density=np.zeros((self.n_samples,1))

        #构造初始值
        if self.h is None:
            self.h=np.std(X)/5
        if sample_weight is None:
            sample_weight=np.ones((self.n_samples,1))
        else:
            sample_weight=sample_weight
        #初始化所有的点为noise
        labels=-np.ones(X.shape[0])
        #对每个样本点找密度吸引子并计算其相应密度
        for i in range(self.n_samples):
            density_attractors[i],density[i],radii[i]=_hill_climb(X[i],X,W=sample_weight,h=self.h,eps=self.eps)

        #初始化簇类 networkx是用来验证簇内的可达性 定义半径为吸引子的领域
        #构造连接图
        cluster_info={}
        num_clusters=0
        cluster_info[num_clusters]={'instances':[0],
                                    'centroid':np.atleast_2d(density_attractors[0])}
        g_clusters=nx.Graph()
        for j1 in range(self.n_samples):
            g_clusters.add_node(j1,attr_dict={'attrator':density_attractors[j1],'radius':radii[j1],'density':density[j1]})

        # 填充群集图
        for j1 in range(self.n_samples):
            for j2 in (x for x in range(self.n_samples)if x!= j1):
                if g_clusters.has_edge(j1,j2):
                    continue
                    diff=np.linalg.norm(g_cluster.node[j1]['attractor']-g_clusters.node[j2]['attractor'])
                    if diff <=(g_clusters.node[j1]['radius']+g_clusters[j1]['radius']):
                        g_clusters.add_edge(j1,j2)

        # 链接聚类
        clusters=list(nx.connected_component_subgraphs(g_clusters))
        num_clusters=0


        for clust in clusters:
        #得到attractors中的最大密度以及相应的点位信息
             max_instance=max(clust,key=lambda x:clust.node[x]['density'])
             max_density=clust.node[max_instance]['density']
             max_centroid=clust.node[max_instance]['attractor']
             complete=False
             c_size=len(clust.nodes())
        if clust.number_of_edges()==(c_size*(c_size-1))/2.:
            complete=True
        cluster_info[num_clusters]={'instances':clust.nodes(),
                                    'size':c_size,
                                    'centroid':max_centroid,
                                    'density':max_density,
                                    'complete':complete}
        #如果类的密度小于要求 则即为Noise点
        if max_density >= self.min_density:
            labels[clust.nodes()]=num_clusters
            num_clusters +=1
            self.clust_info_=cluster_info
            self.labels_=labels
            return self

data=pd.read_csv('iris2.csv')
data=np.array(data)
samples=np.mat(data[:,0:2])
true_labels=data[:,-1]
labels=list(set(true_labels))
true_ID=np.zeros((3,50))
index=range(len(true_labels))
for i in range(len(labels)):
    true_ID[i]=[j for j in index if true_labels[j]==labels[i]]
d=DENCLUE(0.25,0.0001)
d.classify(samples)
right_num=0

for i in range(len(d.clust_info_)):
    bestlens=0
    clust_set=set(d.clust_info_[i]['instances'])
    for j in range(len(labels)):
        true_set=set(true_ID[j])
        and_set=clust_set&true_set
        if len(list(and_set))>bestlens:
            bestlens=len(list(and_set))
    right_num+=bestlens
#输出类的信息以及聚类的纯度
print(d.clust_info_,float(right_num)/len(samples))
